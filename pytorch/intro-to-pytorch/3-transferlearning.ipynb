{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Transfer Learning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "import torch\r\n",
    "from torch import nn\r\n",
    "from torch import optim\r\n",
    "import torch.nn.functional as F\r\n",
    "from torchvision import datasets, transforms, models"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# using CIFAR10 datasets\r\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\r\n",
    "                                       transforms.RandomResizedCrop(224),\r\n",
    "                                       transforms.RandomHorizontalFlip(),\r\n",
    "                                       transforms.ToTensor(),\r\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\r\n",
    "                                                            [0.229, 0.224, 0.225])])\r\n",
    "\r\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\r\n",
    "                                      transforms.CenterCrop(224),\r\n",
    "                                      transforms.ToTensor(),\r\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\r\n",
    "                                                           [0.229, 0.224, 0.225])])\r\n",
    "\r\n",
    "# Download and load the training data\r\n",
    "trainset = datasets.CIFAR10('~/.pytorch/CIFAR10/', download=True, train=True, transform=train_transforms)\r\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\r\n",
    "\r\n",
    "# Download and load the test data\r\n",
    "testset = datasets.CIFAR10('~/.pytorch/CIFAR10/', download=True, train=False, transform=test_transforms)\r\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# transfer learning from DenseNet121\r\n",
    "model = models.densenet121(pretrained=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Freeze parameters so we don't backprop through them\r\n",
    "for param in model.parameters():\r\n",
    "    param.requires_grad = False\r\n",
    "\r\n",
    "from collections import OrderedDict\r\n",
    "classifier = nn.Sequential(OrderedDict([\r\n",
    "                          ('fc1', nn.Linear(1024, 500)),\r\n",
    "                          ('relu', nn.ReLU()),\r\n",
    "                          ('fc2', nn.Linear(500, 10)),\r\n",
    "                          ('output', nn.LogSoftmax(dim=1))\r\n",
    "                          ]))\r\n",
    "    \r\n",
    "model.classifier = classifier"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit"
  },
  "interpreter": {
   "hash": "56eb87fbc954af64301db39dd2250c36693ef9dfda1761c1c472f812d1bbbb95"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}